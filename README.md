# Breast Cancer Prediction MLOps Project

This project demonstrates a foundational MLOps workflow for deploying a Breast Cancer prediction model as a Flask API. It covers project setup, model training, API development, Dockerization, and automated CI/CD with GitHub Actions.

## Project Structure

```
breast-cancer-ops/
├── config/                    # Configuration files
│   ├── docker-compose.yml     # Defines and links multi-container Docker application
│   ├── Dockerfile.api         # Dockerfile for the Flask API container
│   └── Dockerfile.streamlit   # Dockerfile for the Streamlit UI container
├── data/                      # Stores the dataset
│   └── data.csv
├── models/                    # Stores the trained model pipeline (created locally)
│   └── model.joblib
├── src/                       # Source code
│   ├── app.py                 # Flask API for model inference
│   ├── schemas.py             # Defines the request schema for the API
│   ├── model/                 # Machine Learning model components
│   │   ├── __init__.py            # Makes 'model' a Python package
│   │   ├── dat-ingestion.py      # Handles raw data loading
│   │   ├── data_preprocessing.py  # Contains data cleaning and feature preparation
│   │   ├── model_inference.py     # Loads trained pipeline and makes predictions
│   │   ├── model_training.py      # Orchestrates model training and pipeline saving
│   │   └── pipeline_utils.py      # Defines the scikit-learn pipeline structure
│   └── streamlit_app.py       # Streamlit user interface for predictions
├── tests/                     # For unit and integration tests
│   ├── __init__.py            # Makes 'tests' a Python package
│   ├── conftest.py            # Shared pytest fixtures across test files
│   ├── fixtures/
│   │   └── sample_payload.json    # For API/integration tests
│   ├── integration/
│   │   ├── bash_test.sh           # For Linux/macOS or Git Bash
│   │   └── powershell_test.ps1    # For Windows PowerShell
│   ├── unit/
│   │   ├── __init__.py            # Makes 'unit' a Python package
│   │   ├── data_ingestion/        # Tests for src/model/data_ingestion.py
│   │   │   └── test_dat-ingestion.py
│   │   ├── data_preprocessing/    # Tests for src/model/data_preprocessing.py
│   │   │   ├── test_drop_unnecessary_columns.py
│   │   │   ├── test_map_diagnosis_to_numerical.py
│   │   │   └── test_prepare_features_and_target.py
│   │   ├── model_inference/       # Tests for src/model/model_inference.py
│   │   │   ├── test_load_pipeline.py
│   │   │   └── test_predict.py
│   │   ├── model_training/        # Tests for src/model/model_training.py
│   │   │   └── test_train_and_save_pipeline.py
│   │   └── pipeline_utils/        # Tests for src/model/pipeline_utils.py
│   │       └── test_create_breast_cancer_pipeline.py
├── .dockerignore              # Files to exclude from Docker build
├── .gitignore                 # Files to exclude from Git
├── .python-version            # Python version specification
├── pyproject.toml             # Project metadata and dependencies (managed by uv)
├── pytest.ini                 # pytest configuration
├── README.md                  # Project documentation
├── requirements.txt           # Project dependencies (generated by uv for pip compatibility)
└── uv.lock                    # Locked dependency versions (generated by uv for reproducibility)
```

## Setup

Follow these steps to set up the project environment and install dependencies. This project uses `uv` for dependency management, and can also generate a `requirements.txt` file for compatibility with standard `pip` workflows.

### Using `uv` (Recommended for faster setup and reproducibility)

`uv` is a fast Python package installer and virtual environment manager written in Rust.

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Anibalrojo/breast-cancer-mlops-workflow
    cd breast-cancer-ops
    ```

2.  **Install `uv` globally (if you don't have it):**
    ```bash
    python -m pip install uv
    ```

3.  **Create and activate virtual environment:**
    ```bash
    uv venv
    # Then activate the environment. On Windows PowerShell:
    .\.venv\Scripts\Activate.ps1
    # On Linux/macOS:
    source .venv/bin/activate
    ```

4.  **Install dependencies:**
    `uv` will install dependencies defined in `pyproject.toml` and `uv.lock`.
    ```bash
    uv install
    ```

### Using `pip` (Alternative method)

If you prefer to use standard `pip` for dependency management, you can do so by first generating `requirements.txt` with `uv`.

1.  **Generate `requirements.txt`:**
    The `requirements.txt` file is generated from `pyproject.toml` using `uv`.
    ```bash
    uv pip compile pyproject.toml -o requirements.txt
    ```

2.  **Create and activate a virtual environment (using `python -m venv` or `conda`):**
    ```bash
    python -m venv .venv
    # Then activate the environment. On Windows PowerShell:
    .\.venv\Scripts\Activate.ps1
    # On Linux/macOS:
    source .venv/bin/activate
    ```

3.  **Install dependencies using `pip`:**
    ```bash
    pip install -r requirements.txt
    ```

## Running tests

Once the environment is set up and dependencies are installed, you can run the tests:

1.  **Run all tests:**
    Ensure your virtual environment is activated. Then, from the project root directory, run:
    ```bash
    uv run pytest
    ```
    `pytest` will automatically discover and run all test files. For more detailed output, use the verbose flag:
    ```bash
    uv run pytest -v
    ```

2.  **Train the Machine Learning Pipeline:**
    This step will load `data/data.csv`, preprocess it, train the Random Forest classifier within a `scikit-learn` pipeline, evaluate it, and then save the complete trained pipeline to `models/model.joblib`. Ensure your virtual environment is activated and `data/data.csv` is present, then run:
    ```powershell
    uv run python -m src.model.model_training
    ```
    This will train the pipeline and save it as `models/model.joblib`.

3.  **Run the Flask API locally:**
    Ensure your virtual environment is activated and the model pipeline is trained (`models/model.joblib` exists), then run:
    ```bash
    uv run python -m src.app
    ```
    The API will be accessible at `http://127.0.0.1:5000/`. Keep this running in one terminal.

## API usage examples

With the Flask API running locally (as described in the 'Run the Flask API locally' step under 'Running tests'), you can test its endpoints in another terminal:

### 1. Health check (`GET /`)

*   **Endpoint:** `GET http://127.0.0.1:5000/`
*   **Purpose:** Verifies that the service is running and the model is loaded.

    **PowerShell:**
    ```powershell
    Invoke-RestMethod -Uri "http://127.0.0.1:5000/" -Method Get
    ```

    **For Linux/macOS or Git Bash:**
    ```bash
    curl http://127.0.0.1:5000/
    ```

    **Expected Output:**
    ```json
    {
      "model_loaded": true,
      "status": "healthy"
    }
    ```

### 2. Prediction (`POST /predict`)

*   **Endpoint:** `POST http://127.0.0.1:5000/predict`
*   **Purpose:** Receives a JSON payload of features and returns a prediction.
*   **Request Body Example:** `tests/fixtures/sample_payload.json`

*   **Example Usage via Test Scripts:**

    **For Windows PowerShell:**
    ```powershell
    & ".\tests\integration\powershell_test.ps1"
    ```

    **For Linux/macOS or Git Bash:**
    ```bash
    ./tests/integration/bash_test.sh
    ```

    (Ensure the Flask API is running locally as described in the 'Run the Flask API locally' step under 'Running tests' before running these scripts.)

    **Expected Output:**
    ```json
    {
      "prediction": 1,
      "probability_benign": 0.1,
      "probability_malignant": 0.9
    }
    ```
    (Note: `prediction` and `probability` values will depend on your model's output for the given input.)

## Streamlit UI

The Streamlit application (`src/streamlit_app.py`) provides an interactive web interface for making predictions using the Flask API.

1.  **Run the Streamlit application locally:**
    Ensure your virtual environment is activated and the Flask API is running (as described in the 'Run the Flask API locally' step under 'Running tests'), then run:
    ```bash
    streamlit run src/streamlit_app.py
    ```
    The UI will open in your browser, typically at `http://localhost:8501`.

## Dockerization

The project now uses Docker Compose to manage both the Flask API and the Streamlit UI. All Docker configuration files are located in the `config/` directory.

1.  **Build and run with Docker Compose:**
    Ensure the model is trained (`models/model.joblib` exists), then navigate to the project root and run:
    ```bash
    docker compose -f config/docker-compose.yml up --build -d
    ```
    This will build images for `config/Dockerfile.api` and `config/Dockerfile.streamlit`, and start both services.
    The Flask API will be accessible via `http://localhost:5000/` and the Streamlit UI via `http://localhost:8501/`.

2.  **Stop Docker Compose services:**
    ```bash
    docker compose -f config/docker-compose.yml down
    ```
    This will stop and remove all services and their networks.

## Automated CI/CD (GitHub Actions)

A GitHub Actions workflow (`.github/workflows/main.yml`) is configured to automate the following steps on every push to the `main` branch:

1.  **Checkout code:** Gets the latest code from the repository.
2.  **Set up Python and install dependencies:** Prepares the environment for model training.
3.  **Create `models/` directory:** Ensures the directory exists for saving the trained model.
4.  **Train the model:** Runs `python -m src.model.model_training` to train the model and generate `models/model.joblib`.
5.  **Build and Push Docker Compose Images:** Builds both API (`config/Dockerfile.api`) and Streamlit UI (`config/Dockerfile.streamlit`) images and pushes them to Docker Hub.
6.  **Run Docker Compose services (for testing):** Starts both the API and Streamlit UI services in isolated containers.
7.  **Wait for services to be ready:** A robust loop that polls both API (`/`) and Streamlit UI (`/`) endpoints until both are responsive.
8.  **Test health and prediction endpoints:** Executes `curl` commands to verify Flask API functionality.
9.  **Test Streamlit UI is accessible:** Executes `curl` command to verify Streamlit UI responsiveness.
10. **Clean up Docker Compose services:** Stops and removes all test containers and networks.

## Future improvements

To further enhance this MLOps project, consider these advanced steps:

1.  **Input Data Schema Validation in `src/app.py`:** Implement a library like `Pydantic` to define a strict and explicit schema for incoming JSON payloads to the `/predict` endpoint, providing robust data validation and clear error messages.
2.  **Multi-stage Docker Builds:** Optimize the `Dockerfile` by using multi-stage builds. The idea is to reduce the final image size by separating build-time dependencies (e.g., for training) from runtime dependencies (e.g., for serving the API).